{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Watch Product in *jamtangan.com* with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchWindowException, WebDriverException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import traceback\n",
    "\n",
    "from email.message import EmailMessage\n",
    "import ssl, smtplib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supporting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_isoformat(input):\n",
    "    month_dict = {\n",
    "        \"Jan\": \"01\",\n",
    "        \"Feb\": \"02\",\n",
    "        \"Mar\": \"03\",\n",
    "        \"Apr\": \"04\",\n",
    "        \"Mei\": \"05\",\n",
    "        \"Jun\": \"06\",\n",
    "        \"Jul\": \"07\",\n",
    "        \"Ags\": \"08\",\n",
    "        \"Sep\": \"09\",\n",
    "        \"Okt\": \"10\",\n",
    "        \"Nov\": \"11\",\n",
    "        \"Des\": \"12\"\n",
    "    }\n",
    "\n",
    "    for key, value in month_dict.items():\n",
    "        input = input.replace(key, value)\n",
    "    \n",
    "    datetime_object = datetime.strptime(input, \"%d %m %Y, %H:%M WIB\")\n",
    "\n",
    "    date = datetime_object.date()\n",
    "    time = datetime_object.time()\n",
    "\n",
    "    return [date, time]\n",
    "\n",
    "def to_email(name):\n",
    "    name = name.lower().strip()\n",
    "    email = name.replace(\" \", \"\") + \"@gmail.com\"\n",
    "    return email\n",
    "\n",
    "def csv_to_json(csv_file_path, json_file_path):\n",
    "    json_array = []\n",
    "\n",
    "    with open(csv_file_path, encoding='utf-8') as csvf: \n",
    "        csv_reader = csv.DictReader(csvf) \n",
    "\n",
    "        for row in csv_reader: \n",
    "            json_array.append(row)\n",
    "\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as jsonf: \n",
    "        json_string = json.dumps(json_array, indent=4)\n",
    "        jsonf.write(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Product Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product(driver, wait):\n",
    "    product_dict = {\n",
    "        \"Brand\" : \"\",\n",
    "        \"Model No\" : \"\",\n",
    "        \"Series\" : \"\",\n",
    "        \"Gender\" : \"\",\n",
    "        \"Colour\" : \"\",\n",
    "        \"Luminous\" : \"\",\n",
    "        \"Calendar\" : \"\",\n",
    "        \"Water Resistant\" : \"\",\n",
    "        \"Case Diameter (mm)\" : \"\",\n",
    "        \"Strap Material\" : \"\",\n",
    "    }\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \".tab-content .grid\")))\n",
    "    spec_grid = driver.find_element(By.CSS_SELECTOR, \".tab-content .grid\")\n",
    "    spec_list = spec_grid.find_elements(By.CSS_SELECTOR, \".spec-item\")\n",
    "    \n",
    "    for spec in spec_list:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \".leading-6\")))\n",
    "        spec_title = spec.find_element(By.CSS_SELECTOR, \".font-black\").text\n",
    "        data = spec.find_elements(By.CSS_SELECTOR, \".leading-6\")\n",
    "        if spec_title in product_dict.keys():\n",
    "            key = data[0].text.strip()\n",
    "            value = data[1].text.strip()\n",
    "            product_dict[key] = value\n",
    "        elif (spec_title == \"Case Diameter\"):\n",
    "            value = float(data[1].text.replace(\"mm\", \"\").strip())\n",
    "            product_dict[\"Case Diameter (mm)\"] = value\n",
    "    \n",
    "    for (key, value) in product_dict.items():\n",
    "        if value == \"\": product_dict[key] = None\n",
    "\n",
    "    return product_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Sales Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sales(driver, wait):\n",
    "    sales_dict = {\n",
    "        \"Product Name\" : \"\",\n",
    "        \"Brand\" : \"\",\n",
    "        \"Model No\" : \"\",\n",
    "        \"Normal Price\" : \"\",\n",
    "        \"Discounted Price\" : \"\",\n",
    "        \"Discount Percentage\" : \"\",\n",
    "        \"Number of Seen\" : \"\",\n",
    "        \"Number of Sold\" : \"\",\n",
    "        \"Offline Stock Status\" : \"\",\n",
    "        \"Online Stock Status\" : \"\",\n",
    "    }\n",
    "\n",
    "    spec_grid = driver.find_element(By.CSS_SELECTOR, \".tab-content .grid\")\n",
    "    spec_list_raw = spec_grid.find_elements(By.CSS_SELECTOR, \".spec-item\")\n",
    "    for spec in spec_list_raw:\n",
    "        if spec.find_element(By.CSS_SELECTOR, \".font-black\").text in [\"Brand\", \"Model No\"]:\n",
    "            data = spec.find_elements(By.CSS_SELECTOR, \".leading-6\")\n",
    "            key = data[0].text.strip()\n",
    "            value = data[1].text.strip()\n",
    "            sales_dict[key] = value\n",
    "\n",
    "    sales_dict[\"Product Name\"] = driver.find_element(By.TAG_NAME, \"h1\").text.strip()\n",
    "\n",
    "    try:\n",
    "        normal_price = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='test-product-info'] .line-through\").text.strip()\n",
    "    except:\n",
    "        normal_price = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='test-product-info'] .text-xl\").text.strip()\n",
    "    discounted_price = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='test-product-info'] .text-xl\").text.strip()\n",
    "    sales_dict[\"Normal Price\"] = int(normal_price.replace(\"Rp\", \"\").replace(\".\", \"\").strip())\n",
    "    sales_dict[\"Discounted Price\"] = int(discounted_price.replace(\"Rp\", \"\").replace(\".\", \"\").strip())\n",
    "\n",
    "    discount_percentage = (sales_dict[\"Normal Price\"] - sales_dict[\"Discounted Price\"]) / sales_dict[\"Normal Price\"]\n",
    "    sales_dict[\"Discount Percentage\"] = round(discount_percentage * 100, 2)\n",
    "\n",
    "    num_seen = driver.find_element(By.CSS_SELECTOR, \".ic-eye + div > .text-sm\").text.strip()\n",
    "    if (num_seen.__contains__(\"Rb\")):\n",
    "        num_seen = float(num_seen.replace(\" Rb\", \"\").strip()) * 1000\n",
    "    sales_dict[\"Number of Seen\"] = int(num_seen)\n",
    "\n",
    "    num_sold = driver.find_element(By.CSS_SELECTOR, \".ic-cart.mr-1 + div > .text-sm\").text.strip()\n",
    "    if (num_sold.__contains__(\"Rb\")):\n",
    "        num_sold = float(num_sold.replace(\" Rb\", \"\").strip()) * 1000\n",
    "    sales_dict[\"Number of Sold\"] = int(num_sold)\n",
    "\n",
    "    try:\n",
    "        empty_badge = driver.find_element(By.CSS_SELECTOR, \".badge.bg-accent-red\")\n",
    "        if (empty_badge != None and empty_badge.text.strip().__contains__(\"habis\")):\n",
    "            sales_dict[\"Online Stock Status\"] = \"Not Available\"\n",
    "        else:\n",
    "            raise Exception(\"The badge is not empty badge\")\n",
    "    except:\n",
    "        online_stock_status = driver.find_element(By.CSS_SELECTOR, \".stepper-wrapper + div\").text.strip()\n",
    "        if (online_stock_status == \"STOK ONLINE < 5 PCS\"): sales_dict[\"Online Stock Status\"] = \"Low (< 5 PCS)\"\n",
    "        elif (online_stock_status == \"STOK ONLINE > 5 PCS\"): sales_dict[\"Online Stock Status\"] = \"High (>= 5 PCS)\"\n",
    "        else: sales_dict[\"Online Stock Status\"] = \"Unknown\"\n",
    "\n",
    "    try:\n",
    "        offline_empty = driver.find_element(By.CSS_SELECTOR, \"picture.mr-2 + div\")\n",
    "        if (offline_empty != None and offline_empty.text.strip().__contains__(\"Tidak tersedia\")):\n",
    "            sales_dict[\"Offline Stock Status\"] = \"Not Available\"\n",
    "        else:\n",
    "            raise Exception(\"The text is not empty text\")\n",
    "    except:\n",
    "        try:\n",
    "            offline_stock_status = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='store-item-0']\")\n",
    "            if (offline_stock_status != None):\n",
    "                sales_dict[\"Offline Stock Status\"] = \"Available\"\n",
    "        except:\n",
    "            sales_dict[\"Offline Stock Status\"] = \"Unknown\"\n",
    "\n",
    "    return sales_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Customer and Review Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_customer_review(driver, wait):\n",
    "    customer_dict = {\n",
    "        \"Email\" : \"\",\n",
    "        \"Name\" : \"\",\n",
    "        \"Member Status\" : \"\"\n",
    "    }\n",
    "    customer_header = customer_dict.keys()\n",
    "    customer_list = []\n",
    "\n",
    "    review_dict = {\n",
    "        \"Product Name\" : \"\",\n",
    "        \"Email\" : \"\",\n",
    "        \"Date\" : \"\",\n",
    "        \"Time\" : \"\",\n",
    "        \"Rating\" : \"\",\n",
    "        \"Delivery Review\" : \"\",\n",
    "        \"Product Review\" : \"\"\n",
    "    }\n",
    "    review_header = review_dict.keys()\n",
    "    review_list = []\n",
    "\n",
    "    MAX_REVIEW_PER_PRODUCT = 5\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \".pb-14\")))\n",
    "    div_review_pagination = driver.find_element(By.CSS_SELECTOR, \".pb-14\")\n",
    "    try:\n",
    "        max_tab_per_product = int(div_review_pagination.find_elements(By.TAG_NAME, \"li\")[-2].text)\n",
    "    except:\n",
    "        max_tab_per_product = 1\n",
    "\n",
    "    review_count = 0\n",
    "    tab_count = 0\n",
    "    # driver.implicitly_wait(10)\n",
    "    while (review_count < MAX_REVIEW_PER_PRODUCT and tab_count < max_tab_per_product):\n",
    "        time.sleep(1)\n",
    "        rating_div = driver.find_elements(By.CSS_SELECTOR, \".bg-neutral-900.col-span-12\")[1]\n",
    "        review_divs = rating_div.find_elements(By.CSS_SELECTOR, \".p-4.relative\")\n",
    "\n",
    "        for review in review_divs:\n",
    "            reviewer_name = review.find_element(By.CSS_SELECTOR, \".mb-1 .text-base\").text\n",
    "            if (len(reviewer_name) < 3) or (reviewer_name[1] == '*' and reviewer_name[-2] == '*'): continue\n",
    "\n",
    "            product_name = driver.find_element(By.CSS_SELECTOR, \"h1\").text\n",
    "\n",
    "            rating = len(review.find_elements(By.CSS_SELECTOR, \".rating .ic-star-fill\"))\n",
    "            datetime_review = to_isoformat(review.find_element(By.CSS_SELECTOR, \"span.block.text-xxs\").text)\n",
    "            date_review, time_review = datetime_review[0], datetime_review[1]\n",
    "            \n",
    "            paragraph_review = review.find_elements(By.CSS_SELECTOR, \"p\")\n",
    "            delivery_review = \"\"\n",
    "            product_review = \"\"\n",
    "            for par in paragraph_review:\n",
    "                title = par.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "                if title == \"Pengiriman:\": delivery_review = par.text.lstrip(\"Pengiriman: \")\n",
    "                if title == \"Produk:\": product_review = par.text.lstrip(\"Produk: \")\n",
    "                else: continue\n",
    "            if delivery_review == \"\": delivery_review = \"Tidak ada review\"\n",
    "            if product_review == \"\": product_review = \"Tidak ada review\"\n",
    "\n",
    "            member_status = driver.find_element(By.CSS_SELECTOR, \".badge.text-xxs\").text\n",
    "\n",
    "            review_count += 1\n",
    "            if review_count > MAX_REVIEW_PER_PRODUCT: break\n",
    "\n",
    "            customer_result = [to_email(reviewer_name), reviewer_name, member_status]\n",
    "            for key, value in zip(customer_header, customer_result):\n",
    "                customer_dict[key] = value\n",
    "            customer_list.append(customer_dict.copy())\n",
    "        \n",
    "            result_review = [product_name, to_email(reviewer_name), date_review, time_review, rating, delivery_review, product_review]\n",
    "            for key, value in zip(review_header, result_review):\n",
    "                review_dict[key] = value\n",
    "            review_list.append(review_dict.copy())\n",
    "        \n",
    "        tab_count += 1\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \".pb-14\")))\n",
    "        div_review_pagination = driver.find_element(By.CSS_SELECTOR, \".pb-14\")\n",
    "        page_buttons = div_review_pagination.find_elements(By.TAG_NAME, \"li\")\n",
    "        for page_button in page_buttons:\n",
    "            if page_button.text == str(tab_count + 1): \n",
    "                page_button.click()\n",
    "                break\n",
    "\n",
    "    return [customer_list, review_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # instantiate the driver and the wait object\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # define the URL\n",
    "    URL = \"https://www.jamtangan.com/c/jam-tangan\"\n",
    "\n",
    "    # open the URL\n",
    "    driver.maximize_window()\n",
    "    driver.get(URL)\n",
    "\n",
    "    try:\n",
    "        # close the pop-up if it exists\n",
    "        try:\n",
    "            if (driver.find_element(By.ID, \"driver-popover-item\")):\n",
    "                driver.find_element(By.CLASS_NAME, \"driver-close-btn\").click()\n",
    "\n",
    "            time.sleep(3)\n",
    "            if (driver.find_element(By.CSS_SELECTOR, \"button.ng-binding\")):\n",
    "                driver.find_element(By.CSS_SELECTOR, \"button.ng-binding\").click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # expand the brands list in filter sidebar\n",
    "        expand_brand = driver.find_elements(By.CSS_SELECTOR, \".accordion-content-wrapper .cursor-pointer\")[1]\n",
    "        while(expand_brand.text == \"LIHAT LAINNYA\"):\n",
    "            expand_brand.click()\n",
    "            time.sleep(1)\n",
    "            expand_brand = driver.find_elements(By.CSS_SELECTOR, \".accordion-content-wrapper .cursor-pointer\")[1]\n",
    "\n",
    "        # get the brands name and url that eligible to be scraped\n",
    "        brands_raw = driver.find_elements(By.CSS_SELECTOR, \".accordion-content-wrapper\")[1].find_elements(By.TAG_NAME, \"li\")\n",
    "        eliminate = ['Semua Brand', 'Band', 'Strap', 'Bracelet', 'Accessories', 'Jewelry', 'Wallets']\n",
    "        brands = []\n",
    "        for brand in brands_raw:\n",
    "            eliminated = False\n",
    "            for phrase in eliminate:\n",
    "                if (phrase in brand.find_element(By.TAG_NAME, \"label\").text):\n",
    "                    eliminated = True\n",
    "                    break\n",
    "            if not eliminated:\n",
    "                brands.append(brand)\n",
    "        brands = brands[39:]\n",
    "        brands_name = [brand.find_element(By.TAG_NAME, \"label\").text for brand in brands]\n",
    "        brands_url = [brand.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\") for brand in brands]\n",
    "\n",
    "        # declare the container of the tables\n",
    "        product = []\n",
    "        sales = []\n",
    "        customer = []\n",
    "        review = []\n",
    "\n",
    "        # scrape the data by iterating each product through the brands\n",
    "        max_product_per_brand = 20\n",
    "        product_count = 1\n",
    "        for brand_url in brands_url:\n",
    "            driver.get(brand_url)\n",
    "            wait.until(EC.url_to_be(brand_url))\n",
    "            time.sleep(1)\n",
    "            products_tag = driver.find_elements(By.CSS_SELECTOR, \"a[data-testid='product-card-test']\")[:max_product_per_brand]\n",
    "            products_url = [product.get_attribute(\"href\") for product in products_tag]\n",
    "            for product_url in products_url:\n",
    "                try:\n",
    "                    driver.get(product_url)\n",
    "                    wait.until(EC.url_to_be(product_url))\n",
    "                    print(f\"{product_count}. Brand = {brands_name[brands_url.index(brand_url)]} | Product = {product_url}\")\n",
    "                    extracted_product = extract_product(driver, wait)\n",
    "                    extracted_sales = extract_sales(driver, wait)\n",
    "                    extracted_customer = extract_customer_review(driver, wait)[0]\n",
    "                    extracted_review = extract_customer_review(driver, wait)[1]\n",
    "\n",
    "                    product.append(extracted_product)\n",
    "                    sales.append(extracted_sales)\n",
    "                    for item in extracted_customer: \n",
    "                        if (item not in customer):\n",
    "                            customer.append(item)\n",
    "                    for item in extracted_review: review.append(item)\n",
    "                    product_count += 1\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "        driver.close()  \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        pass        \n",
    "\n",
    "    try:\n",
    "        save_dir = r'../data/unprocessed/'\n",
    "\n",
    "        # exporting the product table to csv and json\n",
    "        with open(save_dir + \"product.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=product[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(product)\n",
    "        product_csv_file_path = save_dir + r'product.csv'\n",
    "        product_json_file_path = save_dir + r'product.json'\n",
    "        csv_to_json(product_csv_file_path, product_json_file_path)\n",
    "\n",
    "        # exporting the sales table to csv and json\n",
    "        with open(save_dir + \"sales.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=sales[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(sales)\n",
    "        sales_csv_file_path = save_dir + r'sales.csv'\n",
    "        sales_json_file_path = save_dir + r'sales.json'\n",
    "        csv_to_json(sales_csv_file_path, sales_json_file_path)\n",
    "\n",
    "        # exporting the customer table to csv and json\n",
    "        with open(save_dir + \"customer.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=customer[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(customer)\n",
    "        customer_csv_file_path = save_dir + r'customer.csv'\n",
    "        customer_json_file_path = save_dir + r'customer.json'\n",
    "        csv_to_json(customer_csv_file_path, customer_json_file_path)\n",
    "\n",
    "        # exporting the review table to csv and json\n",
    "        with open(save_dir + \"review.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=review[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(review)\n",
    "        review_csv_file_path = save_dir + r'review.csv'\n",
    "        review_json_file_path = save_dir + r'review.json'\n",
    "        csv_to_json(review_csv_file_path, review_json_file_path)\n",
    "\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        pass\n",
    "    \n",
    "    print(f\"Product Collected = {len(product)}\")\n",
    "    print(f\"Sales Collected = {len(sales)}\")\n",
    "    print(f\"Customer Collected = {len(customer)}\")\n",
    "    print(f\"Review Collected = {len(review)}\")\n",
    "\n",
    "    print(\"\\n========== Scraping is done! ==========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Collected = 692\n",
      "Sales Collected = 692\n",
      "Customer Collected = 1325\n",
      "Review Collected = 1422\n",
      "\n",
      "========== Scraping is done! ==========\n",
      "\n",
      "Time Start:\t2023-07-18 16:28:13\n",
      "Time End:\t2023-07-18 18:24:43\n",
      "Duration:\t1:56:30  \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "if (__name__ == \"__main__\"):\n",
    "    # setup the timer\n",
    "    time_start = datetime.now()\n",
    "\n",
    "    # run the main program\n",
    "    main()\n",
    "\n",
    "    # setup the timer\n",
    "    time_end = datetime.now()\n",
    "    delta = time_end - time_start\n",
    "\n",
    "    text_wrapper = open(r\"Data Scraping\\src\\config\\email_config.txt\", \"r\")\n",
    "\n",
    "    email_config = text_wrapper.readlines()\n",
    "    email_to_notify = email_config[0].strip()\n",
    "    email_password = email_config[1].strip()\n",
    "\n",
    "    text_wrapper.close()\n",
    "\n",
    "    subject = \"Scraping Jamtangan.com Report\"\n",
    "    body = f\"\"\"\n",
    "    [SCRAPING JAMTANGAN.COM IS COMPLETE]\n",
    "\n",
    "    Time Start:\\t{time_start.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "    Time End:\\t{time_end.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "    Duration:\\t{str(delta).split('.')[0]}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    email = EmailMessage()\n",
    "    email[\"From\"] = email_to_notify\n",
    "    email[\"To\"] = email_to_notify\n",
    "    email[\"Subject\"] = subject\n",
    "    email.set_content(body)\n",
    "\n",
    "    context = ssl.create_default_context()\n",
    "\n",
    "    with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\n",
    "        server.login(email_to_notify, email_password)\n",
    "        server.sendmail(email_to_notify, email_to_notify, email.as_string())\n",
    "    \n",
    "    print(f\"Time Start:\\t{time_start.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Time End:\\t{time_end.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Duration:\\t{str(delta).split('.')[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Processing Data Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Jumlah data product yang duplikat: 0\n",
      "===== Jumlah raw data product include bad product: 1339\n",
      "===== Contoh bad product: \n",
      "            Brand               Model No    Series Gender Colour Luminous  \\\n",
      "173  Boda Concept  BC-C1-CF-CARBON-FIBER  C Series                          \n",
      "402           DLW   HANDS-MIL-SPEC-BLACK                                    \n",
      "403           DLW    FLAT-BI-CI-SKX-BLUE                                    \n",
      "\n",
      "    Calendar Water Resistant Case Diameter (mm) Strap Material  \n",
      "173                                                             \n",
      "402                                                             \n",
      "403                                                             \n",
      "===== Jumlah raw data product setelah filtering bad product: 1252\n",
      "===== Jumlah data product yang memiliki nilai kosong: 647\n",
      "===== Jumlah data product yang memiliki nilai kosong setelah dihandle: 0\n"
     ]
    }
   ],
   "source": [
    "# load the product data\n",
    "unprocessed_product_df = pd.read_json(r\"../data/unprocessed/product.json\")\n",
    "\n",
    "# check duplicate data\n",
    "duplicated_product_stat = unprocessed_product_df.duplicated()\n",
    "num_duplicated_product = duplicated_product_stat.sum()\n",
    "\n",
    "print(f\"===== Jumlah data product yang duplikat: {num_duplicated_product}\")\n",
    "\n",
    "# check and handle bad product\n",
    "print(f\"===== Jumlah raw data product include bad product: {len(unprocessed_product_df)}\")\n",
    "missing_amount = unprocessed_product_df.eq(\"\").sum(axis=1)\n",
    "filtered_product_df = unprocessed_product_df[missing_amount <= 2]\n",
    "print(f\"===== Contoh bad product: \\n{unprocessed_product_df[missing_amount > 2].head(3)}\")\n",
    "print(f\"===== Jumlah raw data product setelah filtering bad product: {len(filtered_product_df)}\")\n",
    "\n",
    "# check and handle missing value\n",
    "missing_value = (filtered_product_df == \"\").sum().sum()\n",
    "print(f\"===== Jumlah data product yang memiliki nilai kosong: {missing_value}\")\n",
    "\n",
    "filtered_product_df = filtered_product_df.replace(\"\", \"-\")\n",
    "missing_value = (filtered_product_df == \"\").sum().sum()\n",
    "print(f\"===== Jumlah data product yang memiliki nilai kosong setelah dihandle: {missing_value}\")\n",
    "\n",
    "# export the filtered product data\n",
    "file_path = r\"../data/processed/product.json\"\n",
    "df_json = filtered_product_df.to_json(file_path, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Processing Data Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Jumlah data sales yang duplikat: 0\n",
      "===== Jumlah raw data sales include bad product: 1339\n",
      "===== Jumlah raw data sales setelah filtering bad product: 1252\n"
     ]
    }
   ],
   "source": [
    "# load the sales data\n",
    "unprocessed_sales_df = pd.read_json(r\"../data/unprocessed/sales.json\")\n",
    "\n",
    "# check duplicate data\n",
    "duplicated_sales_stat = unprocessed_sales_df.duplicated()\n",
    "num_duplicated_sales = duplicated_sales_stat.sum()\n",
    "\n",
    "print(f\"===== Jumlah data sales yang duplikat: {num_duplicated_sales}\")\n",
    "\n",
    "# remove sales that include bad product\n",
    "print(f\"===== Jumlah raw data sales include bad product: {len(unprocessed_sales_df)}\")\n",
    "filtered_sales_df = unprocessed_sales_df[\n",
    "    unprocessed_sales_df[\"Brand\"].isin(filtered_product_df[\"Brand\"]) & \n",
    "    unprocessed_sales_df[\"Model No\"].isin(filtered_product_df[\"Model No\"])]\n",
    "print(f\"===== Jumlah raw data sales setelah filtering bad product: {len(filtered_sales_df)}\")\n",
    "\n",
    "# export the filtered sales data\n",
    "file_path = r\"../data/processed/sales.json\"\n",
    "df_json = filtered_sales_df.to_json(file_path, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Processing Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Jumlah raw data review include bad product: 2650\n",
      "===== Jumlah raw data review setelah filtering bad product: 2496\n",
      "===== Jumlah data review yang duplikat: 437\n",
      "===== Data yang duplikat:\n",
      "                                           Product Name  \\\n",
      "17    Alba Prestige ARSY96X1 Men Silver Dial Dual To...   \n",
      "57    Alba Prestige AJ6124X1 Men Silver Dial Dual To...   \n",
      "95    Alexandre Christie Chronograph AC 6141 MC BTBB...   \n",
      "96    Alexandre Christie Chronograph AC 6141 MC BTBB...   \n",
      "97    Alexandre Christie Chronograph AC 6141 MC BTBB...   \n",
      "...                                                 ...   \n",
      "2590  TISSOT T-Sport T116.617.11.047.01 Chrono XL Cl...   \n",
      "2592  TISSOT Luxury Powermatic 80 T086.407.11.201.02...   \n",
      "2594  TISSOT T-Sport T116.617.11.057.01 Chrono XL Cl...   \n",
      "2596  Tissot PR 100 Chronograph Gent White Dial Stai...   \n",
      "2598  Tissot T-Classic T109.407.16.031.00 Everytime ...   \n",
      "\n",
      "                            Email        Date      Time  Rating  \\\n",
      "17         nadhimfaisal@gmail.com  2022-12-15  21:01:00       5   \n",
      "57                melda@gmail.com  2022-03-30  11:09:00       5   \n",
      "95            mmuttaqin@gmail.com  2023-03-05  12:18:00       5   \n",
      "96    hidajatsoegiharto@gmail.com  2023-02-28  22:37:00       5   \n",
      "97            mmuttaqin@gmail.com  2023-03-05  12:18:00       5   \n",
      "...                           ...         ...       ...     ...   \n",
      "2590               deny@gmail.com  2019-02-18  14:37:00       5   \n",
      "2592     wayansudiarsha@gmail.com  2023-04-06  15:56:00       5   \n",
      "2594     mindoedisinaga@gmail.com  0001-01-01  00:00:00       5   \n",
      "2596             cening@gmail.com  2018-02-02  18:20:00       5   \n",
      "2598              andih@gmail.com  0001-01-01  00:00:00       5   \n",
      "\n",
      "             Delivery Review  \\\n",
      "17          Tidak ada review   \n",
      "57          Tidak ada review   \n",
      "95                     cepat   \n",
      "96    Okay, sesuai estimasi.   \n",
      "97                     cepat   \n",
      "...                      ...   \n",
      "2590        Tidak ada review   \n",
      "2592        Tidak ada review   \n",
      "2594        Tidak ada review   \n",
      "2596        Tidak ada review   \n",
      "2598        Tidak ada review   \n",
      "\n",
      "                                         Product Review  \n",
      "17          Barang sesuai deskripsi Packing sangat aman  \n",
      "57                                      Alba sllu keren  \n",
      "95                                      bagus, original  \n",
      "96    Kualitas barang sangat bagus Barang sesuai des...  \n",
      "97                                      bagus, original  \n",
      "...                                                 ...  \n",
      "2590  Yes, finally I found this product at www.jamta...  \n",
      "2592  Kualitas barang sangat bagus, Packing sangat a...  \n",
      "2594  Tissot chrono XL menampilkan bentuk yg menarik...  \n",
      "2596       Kalau beli langsung ke toko alamatnya dimana  \n",
      "2598  Jam yang indah dan elegan dengan harga yang sa...  \n",
      "\n",
      "[437 rows x 7 columns]\n",
      "===== Jumlah data review yang duplikat setelah diproses: 0\n"
     ]
    }
   ],
   "source": [
    "# load the review data\n",
    "unprocessed_review_df = pd.read_json(r\"../data/unprocessed/review.json\")\n",
    "\n",
    "# remove review that include bad product\n",
    "print(f\"===== Jumlah raw data review include bad product: {len(unprocessed_review_df)}\")\n",
    "filtered_review_df = unprocessed_review_df[unprocessed_review_df['Product Name'].isin(filtered_sales_df['Product Name'])]\n",
    "print(f\"===== Jumlah raw data review setelah filtering bad product: {len(filtered_review_df)}\")\n",
    "\n",
    "# check and handle duplicate data\n",
    "duplicated_review_stat = filtered_review_df.duplicated()\n",
    "num_duplicated_review = duplicated_review_stat.sum()\n",
    "duplicated_review_rows = filtered_review_df[duplicated_review_stat]\n",
    "duplicateless_review = filtered_review_df.drop_duplicates()\n",
    "\n",
    "print(f\"===== Jumlah data review yang duplikat: {num_duplicated_review}\")\n",
    "print(f\"===== Data yang duplikat:\\n{duplicated_review_rows}\")\n",
    "print(f\"===== Jumlah data review yang duplikat setelah diproses: {duplicateless_review.duplicated().sum()}\")\n",
    "\n",
    "# export the filtered review data\n",
    "file_path = r\"../data/processed/review.json\"\n",
    "df_json = duplicateless_review.to_json(file_path, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Processing Data Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Jumlah data customer yang duplikat (email yang sama): 229\n",
      "===== Contoh data dengan email yang sama dan member status yang bisa berbeda:\n",
      "                    Email        Name     Member Status\n",
      "1653  abdulazis@gmail.com  Abdul azis  Centurion Member\n",
      "1998  abdulazis@gmail.com  Abdul azis      Basic Member\n",
      "764         ade@gmail.com         Ade     Silver Member\n",
      "2195        ade@gmail.com         Ade      Basic Member\n",
      "1012      agung@gmail.com       agung      Basic Member\n",
      "206       agung@gmail.com       Agung      Basic Member\n",
      "\n",
      "===== Jumlah data customer yang duplikat setelah diproses: 0\n"
     ]
    }
   ],
   "source": [
    "# load the customer data\n",
    "unprocessed_customer_df = pd.read_json(r\"../data/unprocessed/customer.json\")\n",
    "\n",
    "# check and handle duplicate data\n",
    "duplicated_cust_stat = unprocessed_customer_df.duplicated(subset=['Email'])\n",
    "num_duplicated_cust = duplicated_cust_stat.sum()\n",
    "print(f\"===== Jumlah data customer yang duplikat (email yang sama): {num_duplicated_cust}\")\n",
    "\n",
    "print(\"===== Contoh data dengan email yang sama dan member status yang bisa berbeda:\")\n",
    "df_cust_email_sorted = unprocessed_customer_df.sort_values(by='Email')\n",
    "duplicated_cust_stat = df_cust_email_sorted.duplicated(subset='Email', keep=False)\n",
    "duplicated_cust_rows = df_cust_email_sorted[duplicated_cust_stat]\n",
    "print(duplicated_cust_rows[:6])\n",
    "\n",
    "# delete duplicated rows with same email and keep the highest member status\n",
    "duplicateless_cust = df_cust_email_sorted.drop_duplicates(subset='Email', keep='first')\n",
    "\n",
    "print(f\"\\n===== Jumlah data customer yang duplikat setelah diproses: {duplicateless_cust.duplicated(subset=['Email']).sum()}\")\n",
    "\n",
    "# export the filtered customer data\n",
    "file_path = r\"../data/processed/customer.json\"\n",
    "df_json = duplicateless_cust.to_json(file_path, orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
