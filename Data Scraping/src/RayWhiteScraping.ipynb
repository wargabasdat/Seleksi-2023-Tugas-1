{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Muhammad Rafi Haidar\n",
    "\n",
    "Kontak: 18221134@std.stei.itb.ac.id\n",
    "\n",
    "Program untuk melakukan scraping data properti yang dijual di di raywhite.co.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library yang digunakan\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import json\n",
    "import simplejson\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.io.json._json.loads = lambda s, *a, **kw: json.loads(s)\n",
    "pd.io.json._json.loads = lambda s, *a, **kw: simplejson.loads(s)\n",
    "pd.io.json._json.loads = lambda s, *a, **kw: pd.json_normalize(simplejson.loads(s))\n",
    "\n",
    "# URL menuju laman listing\n",
    "URL = 'https://www.raywhite.co.id/jual?tipe={}&order=newest&limit=39&page={}'\n",
    "\n",
    "# XPATH yang dipakai di laman tujuan\n",
    "TITLE_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[1]/h1'\n",
    "LOCATION_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[1]/p[2]'\n",
    "SPEC_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[2]/div[3]/table/tbody/tr[{}]/td[{}]'\n",
    "REALTOR_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[2]/div/h5/a'\n",
    "REALTOR_OFFICE_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[2]/div/div[1]/a'\n",
    "PHONE_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[2]/div/div[2]/a[1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk scraping\n",
    "\n",
    "# extract_title(lxml.etree._Element tree) -> String\n",
    "# Melakukan scraping judul properti\n",
    "def extract_title(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    title_element = tree.xpath(TITLE_XPATH)[0]\n",
    "    title = title_element.text.strip().replace('\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t', ' ') if title_element is not None else \"\"\n",
    "\n",
    "    return title\n",
    "\n",
    "# extract_value_usd(Beautifulsoup Soup) -> Int\n",
    "# Melakukan scraping harga properti\n",
    "def extract_value_usd(soup):\n",
    "    price_card = soup.find('div', class_=\"btn-group btn-group-sm\")\n",
    "    value_usd = price_card.find_all('input')[1]['value']\n",
    "    value_usd = value_usd.replace(\",\", \"\")\n",
    "\n",
    "    try:\n",
    "        value_usd = int(value_usd)\n",
    "    except ValueError:\n",
    "        value_usd = 0\n",
    "        \n",
    "    return value_usd\n",
    "\n",
    "# extract_location(lxml.etree._Element tree) -> Tuple of (String, String)\n",
    "# Melakukan scraping lokasi properti\n",
    "def extract_location(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    location_element = tree.xpath(LOCATION_XPATH)[0]\n",
    "    location = location_element.text.strip() if location_element is not None else \"\"\n",
    "    city, province = location.split(\", \")\n",
    "\n",
    "    return (city, province)\n",
    "\n",
    "\n",
    "# extract_realtor_id(Beautifulsoup Soup) -> Int\n",
    "# Melakukan scraping ID agen yang menjual properti\n",
    "def extract_realtor_id(soup):\n",
    "    url_list = soup.find_all('a', href=True)\n",
    "    agent_url = [a['href'] for a in url_list if a['href'].startswith('https://www.raywhite.co.id/agent/')]\n",
    "    try:\n",
    "        id_str = agent_url[0].split('/')[-2]\n",
    "        return int(id_str)\n",
    "    except (IndexError, ValueError):\n",
    "        return 0\n",
    "    \n",
    "\n",
    "# extract_realtor(lxml.etree._Element tree) -> String\n",
    "# Melakukan scraping nama agen yang menjual properti\n",
    "def extract_realtor(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    realtor_element = tree.xpath(REALTOR_XPATH)[0]\n",
    "    \n",
    "    return realtor_element.text.strip() if realtor_element is not None else \"\"\n",
    "\n",
    "# extract_office(lxml.etree._Element tree) -> String\n",
    "# Melakukan scraping kantor agen yang menjual properti\n",
    "def extract_office(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    office_element = tree.xpath(REALTOR_OFFICE_XPATH)[0]\n",
    "\n",
    "    return office_element.text.strip() if office_element is not None else \"\"\n",
    "\n",
    "# extract_negotiable(Beautifulsoup Soup) -> Bool\n",
    "# Melakukan scraping status negosiasi harga properti\n",
    "def extract_negotiable(soup):\n",
    "    value_element = soup.find('p', class_=\"h3 mb-3\").text.strip()\n",
    "    pattern = re.compile(r\"nego\", re.IGNORECASE)\n",
    "    match = re.search(pattern, value_element)\n",
    "\n",
    "    return bool(match)\n",
    "\n",
    "# extract_phone(lxml.etree._Element tree) -> Int\n",
    "# Melakukan scraping nomor kontak agen yang menjual properti\n",
    "def extract_phone(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    phone_element = tree.xpath(PHONE_XPATH)\n",
    "\n",
    "    if phone_element:\n",
    "        href = phone_element[0].get('href')\n",
    "        phone = href.split(':')[1]\n",
    "\n",
    "        # Hanya mengambil nomor pertama\n",
    "        if \"/\" in phone:\n",
    "            phone = phone.split(\"/\")[0]\n",
    "\n",
    "        # Nomor kosong tidak akan diambil\n",
    "        if (phone == \"\") or (len(phone) == 0):\n",
    "            phone = None\n",
    "            \n",
    "    else:\n",
    "        phone = None\n",
    "    \n",
    "    # Formatting nomor telepon\n",
    "    if (phone != None) and (phone[0] != '+'):\n",
    "        phone = '+' + phone\n",
    "\n",
    "    return phone\n",
    "\n",
    "# extract_specification(lxml.etree._Element tree) -> List of any\n",
    "# Melakukan scraping spesifikasi properti\n",
    "def extract_specification(tree):\n",
    "    retval = [None, None, None, None, None, None, None, None]\n",
    "\n",
    "    for i in range(1, 9):\n",
    "        try:\n",
    "            # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "            label_element = tree.xpath(SPEC_XPATH.format(i, 2))[0]\n",
    "            label = label_element.text.strip() if label_element is not None else \"\"\n",
    "        except IndexError:\n",
    "            return retval\n",
    "        \n",
    "        # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "        value_element = tree.xpath(SPEC_XPATH.format(i, 3))[0]\n",
    "        value = value_element.text.strip().replace(\": \", \"\") if value_element is not None else \"\"\n",
    "        \n",
    "        if label == 'Listing ID':\n",
    "            retval[0] = value\n",
    "            # Ubah ke integer\n",
    "            if (retval[0] != None) and (retval[0] != ''):\n",
    "                retval[0] = int(retval[0])\n",
    "        elif label == 'Live ID':\n",
    "            retval[1] = value.replace(\":\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\", \"\")\n",
    "        elif label == 'Building Size':\n",
    "            retval[2] = value.replace(\" m\", \"\")\n",
    "            # Ubah ke integer\n",
    "            if (retval[2] != None) and (retval[2] != ''):\n",
    "                retval[2] = int(retval[2])\n",
    "        elif label == 'Land Size':\n",
    "            retval[3] = value.replace(\" m\", \"\")\n",
    "            # Ubah ke integer\n",
    "            if (retval[3] != None) and (retval[3] != ''):\n",
    "                retval[3] = int(retval[3])\n",
    "        elif label == 'Certificate':\n",
    "            retval[4] = value\n",
    "        elif label == 'Bedroom':\n",
    "            retval[5] = value\n",
    "            # Ubah ke integer\n",
    "            if (retval[5] != None) and (retval[5] != ''):\n",
    "                retval[5] = int(retval[5])\n",
    "        elif label == 'Bathroom':\n",
    "            retval[6] = value\n",
    "            # Ubah ke integer\n",
    "            if (retval[6] != None) and (retval[6] != ''):\n",
    "                retval[6] = int(retval[6])\n",
    "        elif label == 'Carport':\n",
    "            retval[7] = value\n",
    "            # Ubah ke integer\n",
    "            if (retval[7] != None) and (retval[7] != ''):\n",
    "                retval[7] = int(retval[7])\n",
    "\n",
    "    return retval\n",
    "\n",
    "# extract(lxml.etree._Element tree, Beautifulsoup soup, String type) -> Dictionary\n",
    "# Melakukan scraping properti\n",
    "def extract_property(tree, soup, propertyType):\n",
    "    title = extract_title(tree)\n",
    "    location = extract_location(tree)\n",
    "    value_usd = extract_value_usd(soup)\n",
    "    realtor_id = extract_realtor_id(soup)\n",
    "    realtor = extract_realtor(tree)\n",
    "    office = extract_office(tree) \n",
    "    negotiable = extract_negotiable(soup)\n",
    "    phone = extract_phone(tree)\n",
    "    specification = extract_specification(tree)\n",
    "\n",
    "    return {\n",
    "                'listing_id': specification[0], #0\n",
    "                'live_id': specification[1], #1\n",
    "                'type': propertyType.lower(), #2\n",
    "                'title': title, #3\n",
    "                'province': location[1], #4\n",
    "                'city': location[0], #5\n",
    "                'value_usd': value_usd, #6\n",
    "                'value_idr': value_usd * 15068, #7\n",
    "                'negotiable': negotiable, #8\n",
    "                'building_size': specification[2], #9\n",
    "                'land_size': specification[3], #10\n",
    "                'certificate': specification[4], #11\n",
    "                'bedroom': specification[5], #12\n",
    "                'bathroom': specification[6], #13\n",
    "                'carport': specification[7], #14\n",
    "                'realtor_id': realtor_id, #15\n",
    "                'realtor': realtor, #16\n",
    "                'realtor_phone': phone, #17\n",
    "                'realtor_office': office #18\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi lainnya\n",
    "\n",
    "# save_to_csv(pd.DataFrame dataframe, String propertyType, Int documentCounter)\n",
    "# Membuat berkas CSV untuk mencatat kemajuan proses scraping per properti\n",
    "def save_to_csv(dataframe, propertyType, documentCounter):\n",
    "    output_dir = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\csv_backup'\n",
    "    csv_filename = os.path.join(output_dir, f'raywhite_{propertyType.lower()}_{documentCounter}.csv')\n",
    "    dataframe.to_csv(csv_filename, index=False)\n",
    "\n",
    "# save_to_json(pd.DataFrame dataframe, String propertyType, Int documentCounter)\n",
    "# Membuat berkas JSON untuk mencatat kemajuan proses scraping per properti\n",
    "def save_to_json(dataframe, propertyType, documentCounter):\n",
    "    output_dir = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data'\n",
    "    json_filename = os.path.join(output_dir, f'raywhite_{propertyType.lower()}_{documentCounter}.json')\n",
    "    dataframe.to_json(json_filename, orient='records')\n",
    "\n",
    "# Fungsi untuk menghilangkan outlier berdasarkan harga\n",
    "def clean_value_outlier(group):\n",
    "    Q1 = group['value_usd'].quantile(0.25)\n",
    "    Q3 = group['value_usd'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low = Q1 - (1.5 * IQR)\n",
    "    up = Q3 + (1.5 * IQR)\n",
    "    return group[(group['value_usd'] >= low) & (group['value_usd'] <= up)]\n",
    "\n",
    "# filter(Dictionary entry) -> Boolea\n",
    "# Melakukan proses filtering untuk memastikan entry bersifat valid\n",
    "def filter(entry):\n",
    "    conditions = [\n",
    "        entry['listing_id'] != None and entry['listing_id'] != '', # Listing ID harus ada\n",
    "        entry['title'] != '' and entry['title'] != None, # Judul properti harus ada dan bukan empty string\n",
    "        entry['province'] != '' and entry['province'] != None, # Provinsi dari lokasi properti harus ada dan bukan empty string\n",
    "        entry['city'] != '' and entry['city'] != None, # Kota dari lokasi properti harus ada dan bukan empty string\n",
    "        entry['value_usd'] > 0, # Harga properti harus lebih dari 0 USD\n",
    "        entry['negotiable'] != None, # Status negosiasi properti harus jelas \n",
    "        entry['certificate'] != None, # Sertifikat properti harus ada\n",
    "        entry['realtor_id'] != 0, # ID agen properti harus ada\n",
    "        entry['realtor'] != '' and entry['realtor'] != None, # Nama agen properti harus ada dan bukan empty string\n",
    "        entry['realtor_phone'] != None, # Agen properti harus mempunyai nomor telepon\n",
    "        entry['realtor_office'] != '' and entry['realtor_office'] != None # Kantor agen properti harus ada dan bukan empty string\n",
    "    ]\n",
    "\n",
    "    return all(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melakukan scraping pada tipe properti Office\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [01:21<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti Office telah diubah menjadi dataframe cadangan dan disimpan di raywhite_Office_1.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Melakukan scraping pada tipe properti Shophouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [01:18<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti Shophouse telah diubah menjadi dataframe cadangan dan disimpan di raywhite_Shophouse_1.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Melakukan scraping pada tipe properti Villa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [01:20<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti Villa telah diubah menjadi dataframe cadangan dan disimpan di raywhite_Villa_1.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Melakukan scraping pada tipe properti Warehouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [01:16<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti Warehouse telah diubah menjadi dataframe cadangan dan disimpan di raywhite_Warehouse_1.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Proses scraping telah selesai!\n",
      "\n",
      "Dokumentasi:\n",
      "Banyak entry yang di-scrape:  2340\n",
      "Banyak entry valid valid di dataframe akhir:  1466\n",
      "Persentase entry yang valid: 62.64957264957265%\n",
      "\n",
      "Hasil scraping telah diubah menjadi dataframe dan disimpan di:\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\src\\csv\\raywhite_merged.csv\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\raywhite_merged.json\n",
      "\n",
      "Dataframe gabungan:\n",
      "\n",
      "      listing_id    live_id       type  \\\n",
      "0         395945  L23385527     office   \n",
      "1         395834  L23378878     office   \n",
      "2         395686  L23358645     office   \n",
      "3         395093  L23269397     office   \n",
      "4         394993  L23257306     office   \n",
      "...          ...        ...        ...   \n",
      "1463      368235  L20447744  warehouse   \n",
      "1464      368268  L20449144  warehouse   \n",
      "1465      368138  L20439529  warehouse   \n",
      "1466      367981  L20420512  warehouse   \n",
      "1467      367980  L20417121  warehouse   \n",
      "\n",
      "                                                  title          province  \\\n",
      "0     Dijual Ruko Pusat Kota Surabaya Lokasi Strateg...        Jawa Timur   \n",
      "1                   Kantor siap dipakai di Menara Kadin       DKI Jakarta   \n",
      "2                               Ruko Murah di Palembang  Sumatera Selatan   \n",
      "3     Dijual Ruko 3 Lantai Jl Diponegoro pusat kota ...        Jawa Timur   \n",
      "4     Ruko Pasar Sentral Lippo Cikarang, Ruko Hook D...        Jawa Barat   \n",
      "...                                                 ...               ...   \n",
      "1463                 Ruko di Green Ville, Jakarta Barat       DKI Jakarta   \n",
      "1464  Gudang Green Sedayu Bizpark, Cakung Timur Luas...       DKI Jakarta   \n",
      "1465  Gudang Strategis Pinggir Jalan Raya @Cikarang ...        Jawa Barat   \n",
      "1466  Setia Budi- Kostan Eksklusif 4 Lantai 54 Kamar...       DKI Jakarta   \n",
      "1467           Tanah Plus Kios Depan Chadstone Cikarang        Jawa Barat   \n",
      "\n",
      "                 city  value_usd    value_idr  negotiable  building_size  \\\n",
      "0            Surabaya     171708   2587296144        True          282.0   \n",
      "1     Jakarta Selatan     726456  10946239008        True          167.0   \n",
      "2           Palembang      56135    845842180        True           64.0   \n",
      "3            Surabaya     495311   7463346148        True          285.0   \n",
      "4              Bekasi     161802   2438032536       False          286.0   \n",
      "...               ...        ...          ...         ...            ...   \n",
      "1463    Jakarta Barat     924581  13931586508       False          590.0   \n",
      "1464    Jakarta Timur     217937   3283874716       False          152.0   \n",
      "1465           Bekasi     894862  13483780616       False          300.0   \n",
      "1466  Jakarta Selatan    1915203  28858278804        True         1800.0   \n",
      "1467           Bekasi     363228   5473119504       False          500.0   \n",
      "\n",
      "      land_size   certificate  bedroom  bathroom  carport  realtor_id  \\\n",
      "0          68.0           HGB      NaN       NaN      NaN       19571   \n",
      "1           NaN  SHM/Freehold      NaN       NaN      NaN       25322   \n",
      "2          64.0  SHM/Freehold      NaN       NaN      NaN       25945   \n",
      "3          95.0  SHM/Freehold      NaN       NaN      NaN       26865   \n",
      "4         108.0           HGB      NaN       NaN      NaN       25709   \n",
      "...         ...           ...      ...       ...      ...         ...   \n",
      "1463      249.0  SHM/Freehold      NaN       NaN      NaN       15575   \n",
      "1464      162.0           HGB      NaN       NaN      NaN         944   \n",
      "1465      904.0  SHM/Freehold      NaN       NaN      NaN       25952   \n",
      "1466      880.0  SHM/Freehold      NaN       NaN      NaN       16519   \n",
      "1467      716.0  SHM/Freehold      NaN       NaN      NaN       25709   \n",
      "\n",
      "                     realtor   realtor_phone                    realtor_office  \n",
      "0                    Debby C   +628553008381            Ray White CBD Surabaya  \n",
      "1             Kuncoro Widodo  +6281345268155                 Ray White Menteng  \n",
      "2     TITY MULIANA EKA  YANI  +6282178893294  Ray White Palembang Mangkunegara  \n",
      "3                LEONY HUANG  +6282331942515    Ray White North West Citraland  \n",
      "4        Wahyu Putra Pribadi  +6281219135665                Ray White Cikarang  \n",
      "...                      ...             ...                               ...  \n",
      "1463           Rully Sofyani  +6281382117828                 Ray White Senayan  \n",
      "1464               Gree RWKG  +6281513999388           Ray White Kelapa Gading  \n",
      "1465             Nur Rachman   +628161664333    Ray White Bintaro Trade Center  \n",
      "1466           Ridho Achfada   +628129936949               Ray White Brawijaya  \n",
      "1467     Wahyu Putra Pribadi  +6281219135665                Ray White Cikarang  \n",
      "\n",
      "[1467 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Program Utama\n",
    "\n",
    "# -------- PENTING --------\n",
    "# -  1 PAGE  = 39 ENTRY   -\n",
    "# -  1 JSON  = 15 PAGE    -\n",
    "# -  1 JSON  = 585 ENTRY  -\n",
    "# -------------------------\n",
    "\n",
    "# JSON cadangan akan dibuat setiap 585 entry (15 main page) telah di-parse pada tipe properti tertentu untuk redundancy dan memastikan kemajuan tetap tercatat walaupun terjadi kegagalan\n",
    "# JSON yang dimaksud di bawah adalah JSON cadangan, JSON gabungan akan tetap dibuat saat program berakhir\n",
    "# CSV backup dan gabungan akan dibuat untuk redundancy\n",
    "PAGE_PER_JSON = 15\n",
    "\n",
    "# Entries on raywhite.co.id as of 01/07/2023:\n",
    "# [0] Apartment = 8524 - 14 JSON can be extracted\n",
    "# [1] Commercial = 9925 - 19 JSON can be extracted\n",
    "# [2] Factory = 647 - 1 JSON can be extracted\n",
    "# [3] House = 80798 - 138 JSON can be extracted\n",
    "# [4] Office = 704 - 1 JSON can be extracted\n",
    "# [5] Shophouse = 3856 - 6 JSON can be extracted\n",
    "# [6] Villa = 1288 - 2 JSON can be extracted\n",
    "# [7] Warehouse = 2824 - 4 JSON can be extracted\n",
    "\n",
    "# Jumlah JSON cadangan yang ingin di scrape dari setiap tipe properti\n",
    "APPARTMENT = 2\n",
    "COMMERCIAL = 2\n",
    "FACTORY = 1\n",
    "HOUSE = 20\n",
    "OFFICE = 1\n",
    "SHOPHOUSE = 1\n",
    "VILLA = 1\n",
    "WAREHOUSE = 1\n",
    "\n",
    "# Tipe properti yang ingin di-scrape (tanah belum tersedia saat ini)\n",
    "PROPERTY_TYPE = ('Apartment', 'Commercial', 'Factory', 'House', 'Office', 'Shophouse', 'Villa', 'Warehouse')\n",
    "SCRAPING_TARGET = (APPARTMENT, COMMERCIAL, FACTORY, HOUSE, OFFICE, SHOPHOUSE, VILLA, WAREHOUSE)\n",
    "\n",
    "# Untuk ethical scraping\n",
    "# Nama menggunakan alias untuk alasan keamanan dan kerahasiaan\n",
    "# Alamat email yang tercantum bukan alamat email pribadi ataupun alamat email instansi untuk alasan keamanan dan kerahasiaan\n",
    "# Pemilik website tetap dapat menggunakan alamat email tersebut untuk menghubungi penulis\n",
    "HEADER = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.199 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Name': 'Campus Fox',\n",
    "    'Email': 'rubahkampus@protonmail.com'\n",
    "}\n",
    "\n",
    "# List Akhir\n",
    "final_list = []\n",
    "\n",
    "# Counter Akhir Untuk Dokumentasi\n",
    "main_page_counter = 0\n",
    "\n",
    "for propertyType in range(4, len(PROPERTY_TYPE)):\n",
    "    print(f'Melakukan scraping pada tipe properti {PROPERTY_TYPE[propertyType]}')\n",
    "\n",
    "    pageParsed = SCRAPING_TARGET[propertyType] * PAGE_PER_JSON\n",
    "\n",
    "    # List Sementara\n",
    "    temp_list = []\n",
    "\n",
    "    # Counter Sementara\n",
    "    entry_counter = 0\n",
    "    document_counter = 1\n",
    "\n",
    "    # Progress Bar Agar Kemajuan Mudah Dilihat Mata\n",
    "    pbar = tqdm(total=pageParsed*39, ncols=80)\n",
    "\n",
    "    for page in range(1, pageParsed+1):\n",
    "        main_page_counter += 1\n",
    "        main_response = requests.get(URL.format(PROPERTY_TYPE[propertyType], page), headers=HEADER)\n",
    "        \n",
    "        if main_response.status_code == 200:\n",
    "            main_content = main_response.text\n",
    "            main_soup = BeautifulSoup(main_content, 'html.parser')\n",
    "\n",
    "            url_list = main_soup.find_all('a', href=True)\n",
    "            property_url = [a['href'] for a in url_list if a['href'].startswith('https://www.raywhite.co.id/properti/')]\n",
    "\n",
    "            for property in property_url:\n",
    "                property_response = requests.get(property, headers=HEADER)\n",
    "                if property_response.status_code == 200:\n",
    "                    property_content = property_response.content\n",
    "\n",
    "                    property_soup = BeautifulSoup(property_content, 'html.parser')\n",
    "                    xml_parsed = etree.HTML(str(property_soup))\n",
    "                    \n",
    "                    property_item = extract_property(xml_parsed, property_soup, PROPERTY_TYPE[propertyType])\n",
    "\n",
    "                    # Cek validitas entry\n",
    "                    if filter(property_item):\n",
    "                        temp_list.append(property_item)\n",
    "                        final_list.append(property_item)\n",
    "\n",
    "                    entry_counter += 1\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "\n",
    "                    if entry_counter % 585 == 0:  \n",
    "                        df = pd.DataFrame(temp_list).drop_duplicates()\n",
    "                        save_to_json(df, PROPERTY_TYPE[propertyType], document_counter)\n",
    "                        save_to_csv(df, PROPERTY_TYPE[propertyType], document_counter) # Untuk redundancy\n",
    "                        print(f'Kemajuan scraping pada tipe properti {PROPERTY_TYPE[propertyType]} telah diubah menjadi dataframe cadangan dan disimpan di raywhite_{PROPERTY_TYPE[propertyType]}_{document_counter}.[json|csv]')\n",
    "\n",
    "                        entry_counter = 0\n",
    "                        document_counter += 1\n",
    "                        temp_list = []\n",
    "                \n",
    "                else:\n",
    "                    print('Koneksi Gagal')\n",
    "\n",
    "        else:\n",
    "            print('Koneksi Gagal')\n",
    "\n",
    "    pbar.close()\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "\n",
    "if len(temp_list) > 0:\n",
    "    df = pd.DataFrame(temp_list).drop_duplicates()\n",
    "    save_to_json(df, PROPERTY_TYPE[propertyType], document_counter)\n",
    "    save_to_csv(df, PROPERTY_TYPE[propertyType], document_counter) # Untuk redundancy\n",
    "\n",
    "# Pembuatan JSON dan CSV gabungan\n",
    "df_final = pd.DataFrame(final_list).drop_duplicates()\n",
    "\n",
    "output_dir_json = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data'\n",
    "output_dir_csv = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\csv_backup'\n",
    "\n",
    "csv_filename = os.path.join(output_dir_csv, f'raywhite_merged.csv')\n",
    "json_filename = os.path.join(output_dir_json, f'raywhite_merged.json')\n",
    "\n",
    "df_final.to_csv(csv_filename, index=False)\n",
    "df_final.to_json(json_filename, orient='records')\n",
    "\n",
    "print('Proses scraping telah selesai!\\n')\n",
    "\n",
    "print(f'Dokumentasi:')\n",
    "print('Banyak entry yang di-scrape: ', main_page_counter * 39)\n",
    "print('Banyak entry valid valid di dataframe akhir: ', len(df_final) - 1)\n",
    "print('Persentase entry yang valid: '+str(((len(df_final) - 1) / (main_page_counter * 39)) * 100)+'%')\n",
    "\n",
    "print(f\"\\nHasil scraping telah diubah menjadi dataframe dan disimpan di:\\n{csv_filename}\\n{json_filename}\\n\")\n",
    "\n",
    "print('Dataframe gabungan:\\n')\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me-reset progress bar\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses merging JSON telah selesai!\n",
      "\n",
      "Dokumentasi:\n",
      "Banyak JSON cadangan yang dihasilkan:  29\n",
      "Banyak entry valid valid di dataframe akhir:  9966\n",
      "Persentase entry yang valid: 58.744473916887706%\n",
      "\n",
      "Hasil scraping telah diubah menjadi dataframe dan disimpan di:\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\csv_backup\\raywhite_merged.csv\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\raywhite_merged.json\n",
      "\n",
      "Dataframe gabungan:\n",
      "\n",
      "      listing_id    live_id       type  \\\n",
      "0         396531  L23431461  apartment   \n",
      "1         396517  L23431285  apartment   \n",
      "2         396507  L23431217  apartment   \n",
      "3         396506  L23431201  apartment   \n",
      "4         396482  L23430786  apartment   \n",
      "...          ...        ...        ...   \n",
      "9962      368235  L20447744  warehouse   \n",
      "9963      368268  L20449144  warehouse   \n",
      "9964      368138  L20439529  warehouse   \n",
      "9965      367981  L20420512  warehouse   \n",
      "9966      367980  L20417121  warehouse   \n",
      "\n",
      "                                                  title     province  \\\n",
      "0     Apartemen Hampton Park, luas 105meter di Pondo...  DKI Jakarta   \n",
      "1     Apartemen Sherwood Twr Richmond, Kelapa Gaadin...  DKI Jakarta   \n",
      "2     Apart Siap Huni Di Apart Sky House Tower Jervo...       Banten   \n",
      "3     Apart Siap Huni Di Apart Roseville Soho BSD Ta...       Banten   \n",
      "4     Apart Murah Siap Huni Di Apart Green Lake, Cip...  DKI Jakarta   \n",
      "...                                                 ...          ...   \n",
      "9962                 Ruko di Green Ville, Jakarta Barat  DKI Jakarta   \n",
      "9963  Gudang Green Sedayu Bizpark, Cakung Timur Luas...  DKI Jakarta   \n",
      "9964  Gudang Strategis Pinggir Jalan Raya @Cikarang ...   Jawa Barat   \n",
      "9965  Setia Budi- Kostan Eksklusif 4 Lantai 54 Kamar...  DKI Jakarta   \n",
      "9966           Tanah Plus Kios Depan Chadstone Cikarang   Jawa Barat   \n",
      "\n",
      "                 city  value_usd     value_idr  negotiable  building_size  \\\n",
      "0     Jakarta Selatan   138687.0  2.089736e+09        True          105.0   \n",
      "1       Jakarta Utara   191520.0  2.885823e+09       False          143.0   \n",
      "2           Tangerang    85524.0  1.288676e+09       False           72.0   \n",
      "3           Tangerang    85854.0  1.293648e+09       False           40.0   \n",
      "4     Jakarta Selatan    13208.0  1.990181e+08       False           20.0   \n",
      "...               ...        ...           ...         ...            ...   \n",
      "9962    Jakarta Barat   924581.0  1.393159e+10       False          590.0   \n",
      "9963    Jakarta Timur   217937.0  3.283875e+09       False          152.0   \n",
      "9964           Bekasi   894862.0  1.348378e+10       False          300.0   \n",
      "9965  Jakarta Selatan  1915203.0  2.885828e+10        True         1800.0   \n",
      "9966           Bekasi   363228.0  5.473120e+09       False          500.0   \n",
      "\n",
      "      land_size   certificate  bedroom  bathroom  carport  realtor_id  \\\n",
      "0           NaN  SHM/Freehold      4.0       3.0      NaN       25650   \n",
      "1           NaN    Akta Tanah      3.0       2.0      NaN         941   \n",
      "2          42.0  SHM/Freehold      2.0       1.0      NaN       26937   \n",
      "3          40.0  SHM/Freehold      1.0       1.0      NaN       26937   \n",
      "4          20.0  SHM/Freehold      1.0       1.0      NaN       15716   \n",
      "...         ...           ...      ...       ...      ...         ...   \n",
      "9962      249.0  SHM/Freehold      NaN       NaN      NaN       15575   \n",
      "9963      162.0           HGB      NaN       NaN      NaN         944   \n",
      "9964      904.0  SHM/Freehold      NaN       NaN      NaN       25952   \n",
      "9965      880.0  SHM/Freehold      NaN       NaN      NaN       16519   \n",
      "9966      716.0  SHM/Freehold      NaN       NaN      NaN       25709   \n",
      "\n",
      "                        realtor  realtor_phone  \\\n",
      "0        Emir Hasiholan Siregar   628161352641   \n",
      "1     Julius Ade Tjandrawidjaja    62811886221   \n",
      "2              Intan Nuritasari   628551070971   \n",
      "3              Intan Nuritasari   628551070971   \n",
      "4                  Saiful Anwar  6281399299972   \n",
      "...                         ...            ...   \n",
      "9962              Rully Sofyani  6281382117828   \n",
      "9963                  Gree RWKG  6281513999388   \n",
      "9964                Nur Rachman   628161664333   \n",
      "9965              Ridho Achfada   628129936949   \n",
      "9966        Wahyu Putra Pribadi  6281219135665   \n",
      "\n",
      "                        realtor_office  \n",
      "0           Ray White Kebayoran Barito  \n",
      "1              Ray White Kelapa Gading  \n",
      "2     Ray White Emerald Avenue Bintaro  \n",
      "3     Ray White Emerald Avenue Bintaro  \n",
      "4     Ray White Emerald Avenue Bintaro  \n",
      "...                                ...  \n",
      "9962                 Ray White Senayan  \n",
      "9963           Ray White Kelapa Gading  \n",
      "9964    Ray White Bintaro Trade Center  \n",
      "9965               Ray White Brawijaya  \n",
      "9966                Ray White Cikarang  \n",
      "\n",
      "[9967 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# Melakukan merge dari berkas JSON cadangan untuk membuat berkas JSON dan CSV (untuk redundancy) gabungan\n",
    "# Dibuat apabila terjadi kegagalan koneksi di sesi scraping\n",
    "# Disarankan untuk dilakukan untuk menghilangkan outlier [14/07/2023]\n",
    "\n",
    "json_dir = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data'  \n",
    "csv_dir = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\csv_backup'\n",
    "df_list = []\n",
    "\n",
    "json_counter = 0\n",
    "\n",
    "for file in os.listdir(json_dir):\n",
    "    if file.endswith('.json'):\n",
    "        json_counter += 1\n",
    "        json_path = os.path.join(json_dir, file)\n",
    "        with open(json_path, 'r') as f:\n",
    "            json_data = f.read()\n",
    "\n",
    "        df_temp = pd.read_json(json_data)\n",
    "        df_list.append(df_temp)\n",
    "\n",
    "df_merged = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
    "\n",
    "df_final = df_merged.groupby('type').apply(clean_value_outlier).reset_index(drop=True)\n",
    "\n",
    "json_filename = os.path.join(json_dir, f'raywhite_merged.json')\n",
    "csv_filename = os.path.join(csv_dir, f'raywhite_merged.csv')\n",
    "\n",
    "df_final.to_json(json_filename, orient='records')\n",
    "df_final.to_csv(csv_filename, index=False)\n",
    "\n",
    "print('Proses merging JSON telah selesai!\\n')\n",
    "\n",
    "print(f'Dokumentasi:')\n",
    "print('Banyak JSON cadangan yang dihasilkan: ', json_counter)\n",
    "print('Banyak entry valid valid di dataframe akhir: ', len(df_final) - 1)\n",
    "print('Persentase entry yang valid: '+str(((len(df_final) - 1) / (json_counter * 585)) * 100)+'%')\n",
    "\n",
    "print(f\"\\nHasil scraping telah diubah menjadi dataframe dan disimpan di:\\n{csv_filename}\\n{json_filename}\\n\")\n",
    "\n",
    "print('Dataframe gabungan:\\n')\n",
    "print(df_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
