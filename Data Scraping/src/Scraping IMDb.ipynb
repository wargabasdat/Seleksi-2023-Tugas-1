{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TUGAS 1 SELEKSI ASISTEN LAB BASIS DATA 2023**\n",
        "#Scraping IMDb Website to Get Top 250 Movies of All Time\n",
        "#Josua Adriel Sinabutar     \n",
        "#18221065"
      ],
      "metadata": {
        "id": "ULXCJ_Xb0pSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Import All Libraries that we need"
      ],
      "metadata": {
        "id": "_HGt_uQP1-eG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup #here i used beautiful soup because its the one that is very familiar for me\n",
        "import json # we want to dump the data in json file type\n"
      ],
      "metadata": {
        "id": "k3o-bBjy2G1-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Create the Class of Film Data"
      ],
      "metadata": {
        "id": "EadThnAz2aw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FilmData:\n",
        "    def __init__(self, rank, title, year_created, duration, classification, rating):\n",
        "        self.rank = rank\n",
        "        self.title = title\n",
        "        self.year_created = year_created\n",
        "        self.duration = duration\n",
        "        self.classification = classification\n",
        "        self.rating = rating\n",
        "\n",
        "    def cetakKeLayar(self):\n",
        "        print(f'''\n",
        "        Rank : {self.rank}\n",
        "        Film Title : {self.title}\n",
        "        Year Created: {self.year_created}\n",
        "        Film Duration: {self.duration}\n",
        "        Film Classification: {self.classification}\n",
        "        Film IMDb Rating: {self.rating}\n",
        "        ''') #multiline string literal in Python\n",
        "    def getYear(self):\n",
        "        return self.year_created\n",
        "    def getDuration(self):\n",
        "        return self.duration\n",
        "    def getClassification(self):\n",
        "        return self.classification\n",
        "    def setYear(self, year):\n",
        "        self.year_created = year\n",
        "    def setDuration(self, duration):\n",
        "        self.duration = duration\n",
        "    def setClassification(self, classification):\n",
        "        self.classification = classification"
      ],
      "metadata": {
        "id": "Aqi1J3VL2hpN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Write the Function that Actually Take the Data from IMDb Web"
      ],
      "metadata": {
        "id": "G0oSSsnd2zyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrapeTheWeb(filmList):\n",
        "        url = \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\" #this is our url source\n",
        "        headers = {\n",
        "            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
        "        }#I introduce myself so that i am identified as browser not bot. I tried to state my email, but it didn't work\n",
        "        req = requests.get(url, headers=headers)\n",
        "        print(req) #printing the response\n",
        "        soup = BeautifulSoup(req.text, 'html.parser') #using html parser just because my reference use it :)\n",
        "        films = soup.findAll('li', 'ipc-metadata-list-summary-item sc-bca49391-0 eypSaE cli-parent')\n",
        "        error = False #error identifier\n",
        "        print('Scraping...')\n",
        "        for film in films:\n",
        "            try:\n",
        "                title_with_rank = film.find('h3', 'ipc-title__text').text\n",
        "                rank = title_with_rank.split(\".\")[0].strip()#getting the rank from the title numbering\n",
        "                title = title_with_rank.split(\".\")[1].strip()# getting only the film title\n",
        "                descriptions = film.find('div', class_='sc-14dd939d-5 cPiUKY cli-title-metadata') #the year, duration, and classification are united in one div so i had to take them all together, put it on list, then store it to different variables\n",
        "                if descriptions:\n",
        "                    each = descriptions.find_all('span', class_='sc-14dd939d-6 kHVqMR cli-title-metadata-item')\n",
        "                    each_values = [span.text for span in each]\n",
        "                else:\n",
        "                    each_values = []\n",
        "                year_created = each_values[0] if len(each_values) >= 1 else '9999' #get the year data\n",
        "                duration = each_values[1] if len(each_values) >= 2 else '9999' #get the duration data\n",
        "                classification = each_values[2] if len(each_values) == 3 else 'N/A' #get the classification data\n",
        "                rating = film.find('span', 'ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating').text #get IBDb users rating regarding each film\n",
        "                completeFilm = FilmData(rank, title, year_created, duration, classification, rating) #append all data to a complete data for each film\n",
        "                filmList.append(completeFilm) #append it to the film list\n",
        "                time.sleep(2)#waiting time to keep the \"ethics\"\n",
        "            except:\n",
        "                print(\"Scraping Error!\") #incase the scraping error\n",
        "                error = True\n",
        "        if not error:\n",
        "            print(\"Scraping is finished smoothly! Congrats.\")"
      ],
      "metadata": {
        "id": "NfxPuVrx28_d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **#4. Scraping imdb.com**"
      ],
      "metadata": {
        "id": "YTjLJzGF8HyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "scrapeTheWeb(result)\n",
        "print(len(result))#check whether it contains 250 films"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuHZGtTb8O6t",
        "outputId": "305812a5-474d-49e3-b40f-5dee81e5ca35"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "Scraping...\n",
            "Scraping is finished smoothly! Congrats.\n",
            "250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Data Preprocessing"
      ],
      "metadata": {
        "id": "iU8-_fFTCMp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We try to find if there are some invalid data in the result list. I have set the 'N/A' value if there is nothing to take from the web. Let's check it out."
      ],
      "metadata": {
        "id": "aG2-NuErDuOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "durationError = 0\n",
        "yearError = 0\n",
        "classificationError = 0\n",
        "for t in result:\n",
        "    if (FilmData.getYear(t) == 'N/A'):\n",
        "        yearError += 1\n",
        "    elif (FilmData.getDuration(t) == 'N/A'):\n",
        "        durationError += 1\n",
        "    elif (FilmData.getClassification(t) == 'N/A'):\n",
        "        classificationError += 1\n",
        "print(durationError)\n",
        "print(yearError)\n",
        "print(classificationError)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25dVdqRCMLcz",
        "outputId": "b43f9427-7221-46d9-b20d-073722492f33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found ***one*** error in classification data. Since it is very minor error, I decided to classify that film into 'R' category. This is how i did it."
      ],
      "metadata": {
        "id": "ZlI4HuW8M15_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in result:\n",
        "    if (FilmData.getClassification(t) == 'N/A'):\n",
        "        FilmData.setClassification(t, '18+')\n",
        "        FilmData.cetakKeLayar(t) #to proof that it has been changed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlKfxfvvNKWB",
        "outputId": "f786a879-4879-43ec-ec19-2447e1522efd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "        Rank : 77\n",
            "        Film Title : Das Boot\n",
            "        Year Created: 1981\n",
            "        Film Duration: 2h 29m\n",
            "        Film Classification: 18+\n",
            "        Film IMDb Rating: 8.4\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Voila!** The error data has been fixed. Now all of the data is valid and we are ready to dump it."
      ],
      "metadata": {
        "id": "lONdCyXpOQxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Dump the Data Into JSON Format"
      ],
      "metadata": {
        "id": "F19By8bhNhF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('IMDb 250 Top Movies.json', 'w') as f:\n",
        "        json.dump([obj.__dict__ for obj in result], f, indent=4)"
      ],
      "metadata": {
        "id": "rlfq10iqNoyY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FIN**"
      ],
      "metadata": {
        "id": "ZjfNSc1XRg52"
      }
    }
  ]
}